llama
__pycache__
output/*/*.png
*.png
*.gif
openai_key.txt
temp.py
!output/*.gif
!output/*.txt